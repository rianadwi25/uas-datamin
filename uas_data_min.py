# -*- coding: utf-8 -*-
"""Uas data min.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11QioIh1nOZTNRgSXAU_s4pRHE5Me4WRQ
"""

# REGRESI LINEAR - House Price prediction model

# 1. IMPORT LIBRARIES
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# Set style untuk visualisasi
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

# 2. LOAD DATASET

# Assuming the CSV is comma-separated, try loading with default settings
df = pd.read_csv('/content/sample_data/real_estate_dataset2.csv')

# Untuk demo, saya buat sample data (ganti dengan data asli kamu)
print("\nüìÇ Loading Dataset...")

print("‚úÖ Dataset berhasil dimuat!")
print(f"Jumlah data: {len(df)} baris")

# 3. EXPLORATORY DATA ANALYSIS (EDA)

# Info dataset
print("\nüìä Informasi Dataset:")
print(df.info())

print("\nüìà Statistik Deskriptif:")
print(df.describe())

# Cek missing values
print("\nüîç Missing Values:")
print(df.isnull().sum())

# 4. VISUALISASI DATA

print("\nüìä Membuat Visualisasi...")

# Drop rows with any NaN values for visualization purposes only
df_viz = df.dropna()

# Distribusi variabel numerik
# Exclude 'Address' as it is not a numeric column for distribution plots
numeric_cols = ['Square_Feet', 'Num_Bedrooms', 'Num_Bathrooms',
                'Num_Floors', 'Year_Built', 'Garage_Size', 'Location_Score', 'Distance_to_Center', 'Price']


# Check if df_viz is empty after dropping NaNs
if df_viz.empty:
    print("\n‚ö†Ô∏è After dropping rows with missing values, no data remains for visualization.")
else:
    fig, axes = plt.subplots(3, 3, figsize=(18, 15)) # Adjusted figure size for 9 plots

    axes = axes.flatten() # Flatten the 3x3 array of axes for easier iteration

    for i, col in enumerate(numeric_cols):
        axes[i].hist(df_viz[col], bins=30, color='skyblue', edgecolor='black')
        axes[i].set_title(f'Distribusi {col}', fontsize=12, fontweight='bold')
        axes[i].set_xlabel(col)
        axes[i].set_ylabel('Frekuensi')

    plt.tight_layout()
    plt.savefig('distribusi_variabel.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Correlation Matrix
    print("\nüîó Correlation Matrix:")
    # Calculate correlation only on numeric columns of the cleaned data
    correlation = df_viz[numeric_cols].corr()
    print(correlation)

    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0,
                square=True, linewidths=1, fmt='.2f')
    plt.title('Correlation Matrix - Housing Variables', fontsize=14, fontweight='bold')
    plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Scatter plots with target (Price)
    fig, axes = plt.subplots(3, 3, figsize=(18, 15)) # Adjusted figure size for 8 plots
    features = ['Square_Feet', 'Num_Bedrooms', 'Num_Bathrooms',
                'Num_Floors', 'Year_Built', 'Has_Garden', 'Has_Pool', 'Garage_Size', 'Location_Score', 'Distance_to_Center']


    axes = axes.flatten() # Flatten the 2x3 array of axes for easier iteration

    for i, feature in enumerate(features[:8]): # Iterate only through the first 8 features to fit in the 3x3 subplot
        axes[i].scatter(df_viz[feature], df_viz['Price'], alpha=0.6, color='coral', edgecolor='black')
        axes[i].set_title(f'{feature} vs Price', fontsize=12, fontweight='bold')
        axes[i].set_xlabel(feature)
        axes[i].set_ylabel('Price')

    # Remove the unused subplots if any
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])


    plt.tight_layout()
    plt.savefig('scatter_plots.png', dpi=300, bbox_inches='tight')
    plt.show()

# 5. PERSIAPAN DATA UNTUK MODELING

# Pilih fitur (X) dan target (y)
# Target: Price (harga rumah)
# Features: Square_Feet, Num_Bedrooms, Num_Bathrooms, Num_Floors, Year_Built, Has_Garden, Has_Pool, Garage_Size, Location_Score, Distance_to_Center

X = df[['Square_Feet', 'Num_Bedrooms', 'Num_Bathrooms',
        'Num_Floors', 'Year_Built', 'Has_Garden', 'Has_Pool', 'Garage_Size', 'Location_Score', 'Distance_to_Center']]
y = df['Price']

print(f"\n‚úÖ Fitur (X): {list(X.columns)}")
print(f"‚úÖ Target (y): Price")
print(f"\nüìä Shape X: {X.shape}")
print(f"üìä Shape y: {y.shape}")

# Split data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nüìö Data Training: {len(X_train)} samples")
print(f"üìù Data Testing: {len(X_test)} samples")

# 6. MEMBANGUN MODEL REGRESI LINEAR

# Inisialisasi dan training model
model = LinearRegression()
model.fit(X_train, y_train)

print("\n‚úÖ Model berhasil dilatih!")

# Koefisien regresi
print("\nüìê Koefisien Regresi:")
for feature, coef in zip(X.columns, model.coef_):
    print(f"  - {feature}: {coef:.4f}")

print(f"\nüìç Intercept: {model.intercept_:.4f}")

# Persamaan Regresi
print("\nüìù Persamaan Regresi Linear:")
equation = f"Price = {model.intercept_:.4f}"
for feature, coef in zip(X.columns, model.coef_):
    equation += f" + ({coef:.4f} √ó {feature})"
print(f"  {equation}")

# 7. PREDIKSI

# Prediksi pada data training
y_train_pred = model.predict(X_train)

# Prediksi pada data testing
y_test_pred = model.predict(X_test)

print("\n‚úÖ Prediksi selesai!")

# 8. EVALUASI MODEL

# Metrik evaluasi untuk data training
train_r2 = r2_score(y_train, y_train_pred)
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = np.sqrt(train_mse)
train_mae = mean_absolute_error(y_train, y_train_pred)

# Metrik evaluasi untuk data testing
test_r2 = r2_score(y_test, y_test_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
test_rmse = np.sqrt(test_mse)
test_mae = mean_absolute_error(y_test, y_test_pred)

print("\nüìä HASIL EVALUASI:")
print("\n1. Data Training:")
print(f"   - R¬≤ Score: {train_r2:.4f}")
print(f"   - MSE: {train_mse:.4f}")
print(f"   - RMSE: {train_rmse:.4f}")
print(f"   - MAE: {train_mae:.4f}")

print("\n2. Data Testing:")
print(f"   - R¬≤ Score: {test_r2:.4f}")
print(f"   - MSE: {test_mse:.4f}")
print(f"   - RMSE: {test_rmse:.4f}")
print(f"   - MAE: {test_mae:.4f}")

# Interpretasi R¬≤
print("\nüí° Interpretasi R¬≤ Score:")
if test_r2 >= 0.9:
    print("   Excellent! Model sangat baik dalam memprediksi.")
elif test_r2 >= 0.7:
    print("   Good! Model cukup baik dalam memprediksi.")
elif test_r2 >= 0.5:
    print("   Fair! Model memiliki kemampuan prediksi yang cukup.")
else:
    print("   Poor! Model kurang baik, perlu improvement.")

# 9. VISUALISASI HASIL

# Plot 1: Actual vs Predicted (Testing Data)
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(y_test, y_test_pred, alpha=0.6, color='blue', edgecolor='black')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect Prediction')
plt.xlabel('Actual Price', fontsize=11)
plt.ylabel('Predicted Price', fontsize=11)
plt.title('Actual vs Predicted Price (Test Data)', fontsize=12, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# Plot 2: Residual Plot
plt.subplot(1, 2, 2)
residuals = y_test - y_test_pred
plt.scatter(y_test_pred, residuals, alpha=0.6, color='green', edgecolor='black')
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.xlabel('Predicted Price', fontsize=11)
plt.ylabel('Residuals', fontsize=11)
plt.title('Residual Plot', fontsize=12, fontweight='bold')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot 3: Distribusi Residual
plt.figure(figsize=(10, 5))
plt.hist(residuals, bins=30, color='purple', alpha=0.7, edgecolor='black')
plt.xlabel('Residuals', fontsize=11)
plt.ylabel('Frequency', fontsize=11)
plt.title('Distribution of Residuals', fontsize=12, fontweight='bold')
plt.axvline(x=0, color='r', linestyle='--', lw=2)
plt.grid(True, alpha=0.3)
plt.savefig('residual_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# optional
# 10. CONTOH PREDIKSI MANUAL

# Buat data baru untuk prediksi
new_data = pd.DataFrame({
    'Square_Feet': [150, 200, 120],
    'Num_Bedrooms': [3, 4, 2],
    'Num_Bathrooms': [2, 3, 1],
    'Num_Floors': [2, 3, 1],
    'Year_Built': [2000, 2010, 1995],
    'Has_Garden': [1, 0, 1],
    'Has_Pool': [0, 1, 0],
    'Garage_Size': [40, 50, 30],
    'Location_Score': [7.5, 8.0, 6.0],
    'Distance_to_Center': [5.0, 3.0, 7.0]
})

predictions = model.predict(new_data)

print("\nüîÆ Prediksi untuk data baru:")
for i, pred in enumerate(predictions):
    print(f"\nData {i+1}:")
    print(f"  Input: Square_Feet={new_data.iloc[i]['Square_Feet']:.2f}, "
          f"Num_Bedrooms={new_data.iloc[i]['Num_Bedrooms']:.2f}, "
          f"Num_Bathrooms={new_data.iloc[i]['Num_Bathrooms']:.2f}, "
          f"Num_Floors={new_data.iloc[i]['Num_Floors']:.2f}, "
          f"Year_Built={new_data.iloc[i]['Year_Built']:.2f}, "
          f"Has_Garden={new_data.iloc[i]['Has_Garden']:.2f}, "
          f"Has_Pool={new_data.iloc[i]['Has_Pool']:.2f}, "
          f"Garage_Size={new_data.iloc[i]['Garage_Size']:.2f}, "
          f"Location_Score={new_data.iloc[i]['Location_Score']:.2f}, "
          f"Distance_to_Center={new_data.iloc[i]['Distance_to_Center']:.2f}")
    print(f"  Prediksi Price: ${pred:.2f}")

# 12. SAVE MODEL (OPTIONAL)

import pickle

# Save model
with open('weather_model.pkl', 'wb') as f:
    pickle.dump(model, f)

print("\n‚úÖ Model berhasil disimpan sebagai 'house_price_model.pkl'")

# Cara load model kembali:
# with open('weather_model.pkl', 'rb') as f:
#     loaded_model = pickle.load(f)

print("\n" + "="*50)
print("ANALISIS SELESAI!")
print("="*50)
print("\nüìÅ File yang dihasilkan:")
print("  1. distribusi_variabel.png")
print("  2. correlation_matrix.png")
print("  3. scatter_plots.png")
print("  4. model_evaluation.png")
print("  5. residual_distribution.png")
print("  6. weather_model.pkl")
print("\n‚ú® Semoga sukses dengan tugasnya! ‚ú®")